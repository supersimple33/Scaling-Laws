{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Perplexity Calculations\n",
    "\n",
    "Given a specific dataset please calculate the perplexity of a number of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/addisonhanrattie/Documents/Scaling-Laws/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import random\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/addisonhanrattie/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "Loading cached shuffled indices for dataset at /Users/addisonhanrattie/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-c1eaa46e94dfbfd3.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset : list[str] = load_dataset(\"imdb\", split=\"test\").shuffle(seed=42).select(range(1))[\"text\"] # (seed=42)\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a list of models we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [ # Jagged comments represent models that are too large to fit on my computer\n",
    "    \"cerebras/Cerebras-GPT-111M\", \"cerebras/Cerebras-GPT-256M\", \"cerebras/Cerebras-GPT-590M\", \"cerebras/Cerebras-GPT-1.3B\", \"cerebras/Cerebras-GPT-2.7B\", \"cerebras/Cerebras-GPT-6.7B\", # \"cerebras/Cerebras-GPT-13.7B\",\n",
    "    \"EleutherAI/gpt-neo-125m\", \"EleutherAI/gpt-neo-1.3B\", \"EleutherAI/gpt-neo-2.7B\", \"EleutherAI/gpt-j-6b\", # \"EleutherAI/gpt-neox-20b\",\n",
    "    \"EleutherAI/pythia-70m\", \"EleutherAI/pythia-160m\", \"EleutherAI/pythia-410m\", \"EleutherAI/pythia-1b\", \"EleutherAI/pythia-1.4b\", \"EleutherAI/pythia-2.8b\", \"EleutherAI/pythia-6.9b\", # \"EleutherAI/pythia-12b\",\n",
    "    \"EleutherAI/pythia-70m-deduped\", \"EleutherAI/pythia-160m-deduped\", \"EleutherAI/pythia-410m-deduped\", \"EleutherAI/pythia-1b-deduped\", \"EleutherAI/pythia-1.4b-deduped\", \"EleutherAI/pythia-2.8b-deduped\", \"EleutherAI/pythia-6.9b-deduped\", # \"EleutherAI/pythia-12b-deduped\",\n",
    "    \"mosaicml/mpt-7b\", # \"mosaicml/mpt-30b\",\n",
    "    \"tiiuae/falcon-7b\", # \"tiiuae/falcon-40b\", \"tiiuae/falcon-180b\"\n",
    "    \"bigscience/bloom-560m\", \"bigscience/bloom-1b1\", \"bigscience/bloom-1b7\", \"bigscience/bloom-3b\", \"bigscience/bloom-7b1\", # \"bigscience/bloom\",\n",
    "    \"openlm-research/open_llama_3b\", \"openlm-research/open_llama_7b\", # \"openlm-research/open_llama_13b\",\n",
    "    \"openlm-research/open_llama_3b_v2\", \"openlm-research/open_llama_7b_v2\",\n",
    "    ]\n",
    "\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigscience/bloom-560m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 693/693 [00:00<00:00, 2.89MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.12G/1.12G [01:40<00:00, 11.1MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 222/222 [00:00<00:00, 504kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 14.5M/14.5M [00:00<00:00, 15.3MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 458kB/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigscience/bloom-1b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 693/693 [00:00<00:00, 3.07MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 2.13G/2.13G [02:31<00:00, 14.0MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 222/222 [00:00<00:00, 1.44MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 14.5M/14.5M [00:00<00:00, 15.5MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 353kB/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigscience/bloom-1b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 715/715 [00:00<00:00, 4.80MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 3.44G/3.44G [04:05<00:00, 14.0MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 222/222 [00:00<00:00, 412kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 14.5M/14.5M [00:02<00:00, 6.15MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 114kB/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigscience/bloom-3b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 693/693 [00:00<00:00, 10.5MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 6.01G/6.01G [11:23<00:00, 8.78MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 222/222 [00:00<00:00, 298kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 14.5M/14.5M [00:00<00:00, 16.5MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 258kB/s]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigscience/bloom-7b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 739/739 [00:00<00:00, 3.91MB/s]\n",
      "Downloading (…)model.bin.index.json: 100%|██████████| 27.5k/27.5k [00:00<00:00, 23.1MB/s]\n",
      "Downloading (…)l-00001-of-00002.bin: 100%|██████████| 9.98G/9.98G [12:31<00:00, 13.3MB/s]\n",
      "Downloading shards:  50%|█████     | 1/2 [12:31<12:31, 751.39s/it]"
     ]
    }
   ],
   "source": [
    "perplexities = []\n",
    "for model in models: # CPU 40.0 vs GPU 30.8\n",
    "\tprint(model)\n",
    "\tresult = perplexity.compute(predictions=dataset, model_id=model, add_start_token=False, device=\"cpu\") #device = CPU\n",
    "\tperplexities.append(result[\"mean_perplexity\"])\n",
    "\n",
    "results = dict(zip(models, perplexities))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.mps.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
