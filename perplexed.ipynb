{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Perplexity Calculations\n",
    "\n",
    "Given a specific dataset please calculate the perplexity of a number of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import random\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/addisonhanrattie/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This movie is so daring it doesn\\'t attempt to hide its similarities to The Shining. It lacks the originality to do so. And when it does, near the end, try to cover up its story of \"father goes psycho under influence of sketchy haunted house in a foreign place,\" it does so by stooping to plenty of other already established conventions and ideas. In other words, it reduces itself to mere cliche. But hell, even I enjoy a good predictable horror or thriller as long as there is an interesting story, one filled with violence and gore, somewhere before the film makes the dreadful turn towards the predictable and trite. Well, this film doesn\\'t have a good story and I was really disappointed with it. What \\'Darkness\\' has going for it is remarkable direction and cinematography. It is a film well-shot and carefully constructed full of fun, creepy angles and shots. What \\'Darkness\\' doesn\\'t have going for it is pretty much everything else. To begin with a minor quibble - the editing in this movie is obnoxious. It jumps from one scene to the next, sometimes pointlessly. For example, the old man in the movie (who pretty much carries the background story, later filled in by another character) is underscored by a hamster running circles. I mean, it looks cool the first time, but why continue to use the same image? I guess you\\'d have to see it for yourself, to understand what I mean. Another problem with this movie is Anna Paquin\\'s character who essentially whines throughout the film, crying and caring all too much about everything - she\\'s the film\\'s failed attempt at a character-driven horror film. The movie has scenes of overblown sentimentalism and the family drama it depicts is simply not believable. By the end, \\'Darkness\\' is a muddled melodrama, with a non-involving mystery provided with too simple of an ending. And it\\'s hardly scary.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset : list[str] = load_dataset(\"imdb\", split=\"test\").shuffle().select(range(1000))[\"text\"] # (seed=42)\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a list of models we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\"cerebras/Cerebras-GPT-111M\", \"cerebras/Cerebras-GPT-256M\", \"cerebras/Cerebras-GPT-590M\", \"EleutherAI/pythia-70m\", \"EleutherAI/pythia-160m\"]\n",
    "# models = [\n",
    "#     \"cerebras/Cerebras-GPT-111M\", \"cerebras/Cerebras-GPT-256M\", \"cerebras/Cerebras-GPT-590M\", \"cerebras/Cerebras-GPT-1.3B\", \"cerebras/Cerebras-GPT-2.7B\", \"cerebras/Cerebras-GPT-6.7B\", \"cerebras/Cerebras-GPT-13.7B\",\n",
    "#     \"tiiuae/falcon-7b\", \"tiiuae/falcon-40b\", \"tiiuae/falcon-180b\"\n",
    "#     ]\n",
    "\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.27s/it]\n",
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.61s/it]\n",
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.38s/it]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 567/567 [00:00<00:00, 1.74MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 166M/166M [00:11<00:00, 14.0MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 396/396 [00:00<00:00, 3.28MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 14.7MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<00:00, 846kB/s]\n",
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n",
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cerebras/Cerebras-GPT-111M': 60.59956016540527,\n",
       " 'cerebras/Cerebras-GPT-256M': 44.23777389526367,\n",
       " 'cerebras/Cerebras-GPT-590M': 35.76863822937012,\n",
       " 'EleutherAI/pythia-70m': 56.73602981567383,\n",
       " 'EleutherAI/pythia-160m': 39.108943176269534}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexities = []\n",
    "for model in models:\n",
    "\tresult = perplexity.compute(predictions=dataset, model_id=model, add_start_token=False) #device = CPU\n",
    "\tperplexities.append(result[\"mean_perplexity\"])\n",
    "\n",
    "results = dict(zip(models, perplexities))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.backends.mps.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
