{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Perplexity Calculations\n",
    "\n",
    "Given a specific dataset please calculate the perplexity of a number of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import random\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " 'Cove at Dardenne Subdivision is located in St Charles County, Missouri.\\nThe following school information for Cove at Dardenne Subdivision may or may not be up to date. School districts and area assignments can often change. For current information make sure to contact the school. Also note not all area private schools may be listed here.')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMDB Dataset\n",
    "# dataset : list[str] = load_dataset(\"imdb\", split=\"test\").shuffle(seed=42).select(range(1000))[\"text\"] # (seed=42)\n",
    "\n",
    "# C4 Dataset\n",
    "dataset = load_dataset(\"c4\", \"en\", split=\"validation\", streaming=True).shuffle(seed=42*42).take(10).select_columns(\"text\")\n",
    "dataset : list[str] = [x[\"text\"] for x in dataset]\n",
    "\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a list of models we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [ # Jagged comments represent models that are too large to fit on my computer\n",
    "    # \"cerebras/Cerebras-GPT-111M\", \"cerebras/Cerebras-GPT-256M\", \"cerebras/Cerebras-GPT-590M\", # \"cerebras/Cerebras-GPT-1.3B\", \"cerebras/Cerebras-GPT-2.7B\", # \"cerebras/Cerebras-GPT-6.7B\", # \"cerebras/Cerebras-GPT-13.7B\",\n",
    "    # \"EleutherAI/gpt-neo-125m\", \"EleutherAI/gpt-neo-1.3B\", \"EleutherAI/gpt-neo-2.7B\", # \"EleutherAI/gpt-j-6b\", # \"EleutherAI/gpt-neox-20b\",\n",
    "    \"EleutherAI/pythia-70m\", # \"EleutherAI/pythia-160m\", \"EleutherAI/pythia-410m\", # \"EleutherAI/pythia-1b\", \"EleutherAI/pythia-1.4b\", \"EleutherAI/pythia-2.8b\", # \"EleutherAI/pythia-6.9b\", # \"EleutherAI/pythia-12b\",\n",
    "    # \"EleutherAI/pythia-70m-deduped\", \"EleutherAI/pythia-160m-deduped\", \"EleutherAI/pythia-410m-deduped\", \"EleutherAI/pythia-1b-deduped\", \"EleutherAI/pythia-1.4b-deduped\", \"EleutherAI/pythia-2.8b-deduped\", # \"EleutherAI/pythia-6.9b-deduped\", # \"EleutherAI/pythia-12b-deduped\",\n",
    "    # \"mosaicml/mpt-7b\", # \"mosaicml/mpt-30b\",\n",
    "    # \"tiiuae/falcon-7b\", # \"tiiuae/falcon-40b\", \"tiiuae/falcon-180b\"\n",
    "    # \"bigscience/bloom-560m\", \"bigscience/bloom-1b1\", \"bigscience/bloom-1b7\", \"bigscience/bloom-3b\", # \"bigscience/bloom-7b1\", # \"bigscience/bloom\",\n",
    "    # \"openlm-research/open_llama_3b\", # \"openlm-research/open_llama_7b\", # \"openlm-research/open_llama_13b\",\n",
    "    # \"openlm-research/open_llama_3b_v2\", # \"openlm-research/open_llama_7b_v2\",\n",
    "    ]\n",
    "\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/pythia-70m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4714ab2ae6f340349452afde460a2d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'perplexities': [50.6631965637207, 52.62197494506836, 27.31839370727539, 191.73825073242188, 37.18301010131836, 30.540359497070312, 70.19187927246094, 33.867462158203125, 73.44882202148438, 138.1171875], 'mean_perplexity': 70.56905364990234}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EleutherAI/pythia-70m': 70.56905364990234}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexities = []\n",
    "for model in models: # CPU 40.0 vs GPU 30.8 # watch batch sizes to free up memory\n",
    "\tprint(model)\n",
    "\t# REVIEW: tune arguments\n",
    "\tresult = perplexity.compute(predictions=dataset, batch_size=16, model_id=model, add_start_token=False, device=\"mps\") #device = CPU\n",
    "\tperplexities.append(result[\"mean_perplexity\"]) # NOTE: we could also take into account mean perplexities\n",
    "\tprint(result)\n",
    "\n",
    "results = dict(zip(models, perplexities))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.mps.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
